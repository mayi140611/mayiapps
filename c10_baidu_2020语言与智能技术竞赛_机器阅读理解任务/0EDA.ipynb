{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020语言与智能技术竞赛：机器阅读理解任务\n",
    "https://aistudio.baidu.com/aistudio/competition/detail/28\n",
    "\n",
    "机器阅读理解 (MRC, Machine Reading Comprehension) 是指让机器阅读文本，然后回答和阅读内容相关的问题。阅读理解是自然语言处理和人工智能领域的重要前沿课题，对于提升机器的智能水平、使机器具有持续知识获取的能力等具有重要价值，近年来受到学术界和工业界的广泛关注。\n",
    "\n",
    "中国中文信息学会(CCF, the China Computer Federation)、中国计算机学会(CIPS, Chinese Information Processing Society of China)和百度公司已经于2018和2019年连续联合举办了机器阅读理解评测，极大地推动了中文机器阅读理解技术的发展。随着技术的进步，当前的一些模型已经能够在一些阅读理解测试集上取得较好的性能。但在实际应用中，这些模型所表现出的鲁棒性仍然较差。因此，“2020 语言与智能技术竞赛”将继续举办机器阅读理解任务的评测，重点关注阅读理解模型在真实应用场景中的鲁棒性，挑战模型的过敏感性、过稳定性以及泛化能力等。\n",
    "\n",
    "本次评测将提供面向真实应用场景的高质量中文阅读理解数据集DuReader Robust，旨在为研究者和开发者提供学术和技术交流的平台， 进一步提升机器阅读理解的研究水平，推动语言理解和人工智能领域技术和应用的发展。本次竞赛将在第五届“语言与智能高峰论坛”举办技术交流论坛和颁奖仪式。 诚邀学术界和工业界的研究者和开发者参加本次竞赛！\n",
    "\n",
    "## 赛程安排\n",
    "    2020/3/10 \t启动竞赛报名，发放样例数据\n",
    "    2020/3/31 \t开放评测入口和排行榜，对报名者发放全部训练数据和第一批测试数据\n",
    "    2020/5/12 \t报名截止\n",
    "    2020/5/13 \t发放最终测试数据\n",
    "    2020/5/20 \t系统结果提交截止\n",
    "    2020/5/30 \t公布竞赛结果，接收系统报告和论文\n",
    "    2020/6/30 \t论文提交截止日期\n",
    "    2020/7 \t在“语言与智能高峰论坛”上交流和颁奖\n",
    "\n",
    "## 数据介绍 Data\n",
    "\n",
    "本次竞赛数据集共包含约21K问题，其中包括15K训练集，约1.4K领域内开发集和5K测试集。测试集包含了领域内测试集和鲁棒性测试集，其中鲁棒性测试集包括了过敏感测试集、过稳定测试集以及泛化能力测试集。全部数据集将分为4个部分供参赛用户下载：\n",
    "\n",
    "1.训练集：共15K样本，用于竞赛模型训练。\n",
    "2.开发集：共1.4K样本，包含答案，用于竞赛模型训练和参数调试。\n",
    "3.测试集1：共2K个样本，主要包含了大部分领域内测试集和少部分鲁棒性测试集，不提供参考答案，用于参赛者在比赛平台上自助验证模型效果。为了防止针对测试集的调试，数据中将会额外加入混淆数据。\n",
    "4.测试集2：是本次竞赛最终测试数据（含测试集1），共5K问题，包含全部领域内测试集和鲁棒性测试集，不提供参考答案。为了防止针对测试集的调试，数据中将会额外加入混淆数据。该部分数据结果不能在比赛平台上自助验证。\n",
    "### 数据样本 Data Sample\n",
    "\n",
    "平台提供的数据为JSON文件格式，样例如下:\n",
    "\n",
    "    {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"paragraphs\": [\n",
    "                    {\n",
    "                        \"qas\": [\n",
    "                            {\n",
    "                                \"question\": \"非洲气候带\", \n",
    "                                \"id\": \"bd664cb57a602ae784ae24364a602674\", \n",
    "                                \"answers\": [\n",
    "                                    {\n",
    "                                        \"text\": \"热带气候\", \n",
    "                                        \"answer_start\": 45\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        ], \n",
    "                        \"context\": \"1、全年气温高，有热带大陆之称。主要原因在与赤道穿过大陆中部，位于南北纬30度之间，主要是热带气候，没有温带和寒带… \n",
    "                    }, \n",
    "                    {\n",
    "                        \"qas\": [\n",
    "                            {\n",
    "                                \"question\": \"韩国全称\", \n",
    "                                \"id\": \"a7eec8cf0c55077e667e0d85b45a6b34\", \n",
    "                                \"answers\": [\n",
    "                                    {\n",
    "                                        \"text\": \"大韩民国\", \n",
    "                                        \"answer_start\": 5\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        ], \n",
    "                        \"context\": \"韩国全称“大韩民国”，位于朝鲜半岛南部，隔“三八线”与朝鲜民主主义人民共和国相邻，面积9.93万平方公理… \"\n",
    "                    }\n",
    "                ], \n",
    "                \"title\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline by苏剑林\n",
    "* 百度LIC2020的机器阅读理解赛道，非官方baseline\n",
    "* 直接用RoBERTa+Softmax预测首尾\n",
    "* BASE模型在第一期测试集上能达到0.69的F1，优于官方baseline\n",
    "* 如果你显存足够，可以换用RoBERTa Large模型，F1可以到0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Layer, Dense, Permute\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 基本信息\n",
    "maxlen = 256\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "learing_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dir = '/Users/luoyonggui/Documents/nlpdata/chinese_roberta_wwm_ext_L-12_H-768_A-12'\n",
    "config_path = f'{bert_dir}/bert_config.json'\n",
    "checkpoint_path = f'{bert_dir}/bert_model.ckpt'\n",
    "dict_path = f'{bert_dir}/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    D = []\n",
    "    for d in json.load(open(filename))['data'][0]['paragraphs']:\n",
    "        for qa in d['qas']:\n",
    "            D.append([\n",
    "                qa['id'], d['context'], qa['question'],\n",
    "                [a['text'] for a in qa.get('answers', [])]\n",
    "            ])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, None, 2)      1538        Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "masked_softmax_1 (MaskedSoftmax (None, None, 2)      0           dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 2, None)      0           masked_softmax_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 101,678,594\n",
      "Trainable params: 101,678,594\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "train_data = load_data(\n",
    "    'data_origin/dureader_robust-data/train.json'\n",
    ")\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "\n",
    "def search(pattern, sequence):\n",
    "    \"\"\"从sequence中寻找子串pattern\n",
    "    如果找到，返回第一个下标；否则返回-1。\n",
    "    \"\"\"\n",
    "    n = len(pattern)\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i + n] == pattern:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, item in self.sample(random):\n",
    "            context, question, answers = item[1:]\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                question, context, max_length=maxlen\n",
    "            )\n",
    "            a = np.random.choice(answers)\n",
    "            a_token_ids = tokenizer.encode(a)[0][1:-1]\n",
    "            start_index = search(a_token_ids, token_ids)\n",
    "            if start_index != -1:\n",
    "                labels = [[start_index], [start_index + len(a_token_ids) - 1]]\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "                batch_labels.append(labels)\n",
    "                if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                    batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                    batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                    batch_labels = sequence_padding(batch_labels)\n",
    "                    yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                    batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "\n",
    "\n",
    "class MaskedSoftmax(Layer):\n",
    "    \"\"\"在序列长度那一维进行softmax，并mask掉padding部分\n",
    "    \"\"\"\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask, 2)\n",
    "            inputs = inputs - (1.0 - mask) * 1e12\n",
    "        return K.softmax(inputs, 1)\n",
    "\n",
    "\n",
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    ")\n",
    "\n",
    "output = Dense(2)(model.output)\n",
    "output = MaskedSoftmax()(output)\n",
    "output = Permute((2, 1))(output)\n",
    "\n",
    "model = Model(model.input, output)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_true = K.one_hot(y_true, K.shape(y_pred)[2])\n",
    "    # 计算交叉熵\n",
    "    return K.mean(K.categorical_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def sparse_accuracy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    # 计算准确率\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=2), 'int32')\n",
    "    return K.mean(K.cast(K.equal(y_true, y_pred), K.floatx()))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=sparse_categorical_crossentropy,\n",
    "    optimizer=Adam(learing_rate),\n",
    "    metrics=[sparse_accuracy]\n",
    ")\n",
    "\n",
    "\n",
    "def extract_answer(question, context, max_a_len=16):\n",
    "    \"\"\"抽取答案函数\n",
    "    \"\"\"\n",
    "    max_q_len = 64\n",
    "    q_token_ids = tokenizer.encode(question, max_length=max_q_len)[0]\n",
    "    c_token_ids = tokenizer.encode(\n",
    "        context, max_length=maxlen - len(q_token_ids) + 1\n",
    "    )[0]\n",
    "    token_ids = q_token_ids + c_token_ids[1:]\n",
    "    segment_ids = [0] * len(q_token_ids) + [1] * (len(c_token_ids) - 1)\n",
    "    c_tokens = tokenizer.tokenize(context)[1:-1]\n",
    "    mapping = tokenizer.rematch(context, c_tokens)\n",
    "    probas = model.predict([[token_ids], [segment_ids]])[0]\n",
    "    probas = probas[:, len(q_token_ids):-1]\n",
    "    start_end, score = None, -1\n",
    "    for start, p_start in enumerate(probas[0]):\n",
    "        for end, p_end in enumerate(probas[1]):\n",
    "            if end >= start and end < start + max_a_len:\n",
    "                if p_start * p_end > score:\n",
    "                    start_end = (start, end)\n",
    "                    score = p_start * p_end\n",
    "    start, end = start_end\n",
    "    return context[mapping[start][0]:mapping[end][-1] + 1]\n",
    "\n",
    "\n",
    "def predict_to_file(infile, out_file):\n",
    "    \"\"\"预测结果到文件，方便提交\n",
    "    \"\"\"\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    R = {}\n",
    "    for d in tqdm(load_data(infile)):\n",
    "        a = extract_answer(d[2], d[1])\n",
    "        R[d[0]] = a\n",
    "    R = json.dumps(R, ensure_ascii=False, indent=4)\n",
    "    fw.write(R)\n",
    "    fw.close()\n",
    "\n",
    "\n",
    "def evaluate(filename):\n",
    "    \"\"\"评测函数（官方提供评测脚本evaluate.py）\n",
    "    \"\"\"\n",
    "    predict_to_file(filename, filename + '.pred.json')\n",
    "    metrics = json.loads(\n",
    "        os.popen(\n",
    "            'python data_origin/dureader_robust-data/evaluate.py %s %s'\n",
    "            % (filename, filename + '.pred.json')\n",
    "        ).read().strip()\n",
    "    )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估和保存模型\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_f1 = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = evaluate(\n",
    "            'data_origin/dureader_robust-data/dev.json'\n",
    "        )\n",
    "        if metrics['F1'] >= self.best_val_f1:\n",
    "            self.best_val_f1 = metrics['F1']\n",
    "            model.save_weights('best_model.weights')\n",
    "        metrics['BEST F1'] = self.best_val_f1\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('best_model.weights')\n",
    "# predict_to_file('/root/baidu/datasets/rc/dureader_robust-test1/test1.json', 'rc_pred.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
