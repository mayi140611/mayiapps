{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O2O商铺食品安全相关评论发现\n",
    "\n",
    "https://www.datafountain.cn/competitions/370\n",
    "    \n",
    "## 赛题背景\n",
    "互联网经济蓬勃发展的背景下,食品经营模式发生了天翻地覆的变化,人们的消费习惯也悄然发生了转变。通过点击手机APP上自己喜欢的食品,这些食品就能按时准确送达指定的区域，这就是当下最受学生和白领喜欢的外卖。然而随着其迅猛发展带来了一定的食品安全隐患，食品安全事故的发生对消费者、外卖平台、食品商家和社会的危害性远远超出想象。  \n",
    "本赛题旨在通过对O2O店铺评论的监测，加强对店铺的食品安全监管。\n",
    "\n",
    "## 赛题任务\n",
    "本赛题提供了10000条对O2O店铺的评论文本训练数据，分为与食品安全有关和与食品安全无关两个类别。参赛者需要根据训练集构造文本分类模型，预测2000条测试集中的评论是否与食品安全有关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析\n",
    "简单看了一下，就是文本2分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)  # 设置显示数据的最大列数，防止出现省略号…，导致数据显示不全\n",
    "pd.set_option('expand_frame_repr', False)  # 当列太多时不自动换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_origin/train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label\tcomment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>0\\t老顾客了。但是味道没有以前好了。才炸好得。吃起来很闷的感觉。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0\\t面条不错，蛮好吃，去过很多次，满是喜欢，下次还去</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>0\\t服务很好，会详细的介绍各类奶茶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0\\t第二次来乐。 好。菜新鲜。种类多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>1\\t辣翅臭了，不知道放了多久。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1\\t我想说里脊肉是有味道的，手抓饼也有臭味，这个怎么吃，差评，差得不能再差！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>0\\t还不错，味道也不错，还有环境也不错</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>0\\t老顾客。好久没有光顾了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>0\\t环境不错、服务也挺好、上菜也很快</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>0\\t环境不错，味道可以，满意，服务很不错哟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               label\\tcomment\n",
       "1962        0\\t老顾客了。但是味道没有以前好了。才炸好得。吃起来很闷的感觉。\n",
       "8527              0\\t面条不错，蛮好吃，去过很多次，满是喜欢，下次还去\n",
       "9623                       0\\t服务很好，会详细的介绍各类奶茶\n",
       "660                       0\\t第二次来乐。 好。菜新鲜。种类多\n",
       "2796                         1\\t辣翅臭了，不知道放了多久。\n",
       "1155  1\\t我想说里脊肉是有味道的，手抓饼也有臭味，这个怎么吃，差评，差得不能再差！\n",
       "8543                     0\\t还不错，味道也不错，还有环境也不错\n",
       "4708                           0\\t老顾客。好久没有光顾了\n",
       "6453                      0\\t环境不错、服务也挺好、上菜也很快\n",
       "1812                   0\\t环境不错，味道可以，满意，服务很不错哟"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label\\tcomment'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label\\tcomment'].str.split('\\t').str.get(0)\n",
    "df['comment'] = df['label\\tcomment'].str.split('\\t').str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/7j/kgtjln3x2dj2g2v57d5vncyw0000gp/T/jieba.cache\n",
      "Loading model cost 0.848 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "def t(s):\n",
    "    return ' '.join(jieba.lcut(s))\n",
    "df['word_seg'] = df.comment.map(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train'] = df.word_seg + ' __label__' + df.label + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label\tcomment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>word_seg</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t一如既往地好吃，希望可以开到其他城市</td>\n",
       "      <td>0</td>\n",
       "      <td>一如既往地好吃，希望可以开到其他城市</td>\n",
       "      <td>一如既往 地 好吃 ， 希望 可以 开 到 其他 城市</td>\n",
       "      <td>一如既往 地 好吃 ， 希望 可以 开 到 其他 城市 __label__0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t味道很不错，分量足，客人很多，满意</td>\n",
       "      <td>0</td>\n",
       "      <td>味道很不错，分量足，客人很多，满意</td>\n",
       "      <td>味道 很 不错 ， 分量 足 ， 客人 很多 ， 满意</td>\n",
       "      <td>味道 很 不错 ， 分量 足 ， 客人 很多 ， 满意 __label__0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...</td>\n",
       "      <td>0</td>\n",
       "      <td>下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...</td>\n",
       "      <td>下雨天 来 的 ， 没有 想象 中 那么 火爆 。 环境 非常 干净 ， 古色古香 的 ， ...</td>\n",
       "      <td>下雨天 来 的 ， 没有 想象 中 那么 火爆 。 环境 非常 干净 ， 古色古香 的 ， ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t真心不好吃 基本上没得好多味道</td>\n",
       "      <td>0</td>\n",
       "      <td>真心不好吃 基本上没得好多味道</td>\n",
       "      <td>真心 不 好吃   基本上 没 得 好多 味道</td>\n",
       "      <td>真心 不 好吃   基本上 没 得 好多 味道 __label__0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "      <td>0</td>\n",
       "      <td>少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "      <td>少送 一个 牛肉 汉堡   而且 也 不 好吃   特别 是 鸡肉 卷   * * 都 不想...</td>\n",
       "      <td>少送 一个 牛肉 汉堡   而且 也 不 好吃   特别 是 鸡肉 卷   * * 都 不想...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      label\\tcomment label                                            comment                                           word_seg                                              train\n",
       "0                              0\\t一如既往地好吃，希望可以开到其他城市     0                                 一如既往地好吃，希望可以开到其他城市                        一如既往 地 好吃 ， 希望 可以 开 到 其他 城市           一如既往 地 好吃 ， 希望 可以 开 到 其他 城市 __label__0\\n\n",
       "1                               0\\t味道很不错，分量足，客人很多，满意     0                                  味道很不错，分量足，客人很多，满意                        味道 很 不错 ， 分量 足 ， 客人 很多 ， 满意           味道 很 不错 ， 分量 足 ， 客人 很多 ， 满意 __label__0\\n\n",
       "2  0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...     0  下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...  下雨天 来 的 ， 没有 想象 中 那么 火爆 。 环境 非常 干净 ， 古色古香 的 ， ...  下雨天 来 的 ， 没有 想象 中 那么 火爆 。 环境 非常 干净 ， 古色古香 的 ， ...\n",
       "3                                 0\\t真心不好吃 基本上没得好多味道     0                                    真心不好吃 基本上没得好多味道                            真心 不 好吃   基本上 没 得 好多 味道               真心 不 好吃   基本上 没 得 好多 味道 __label__0\\n\n",
       "4           0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道     0              少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道  少送 一个 牛肉 汉堡   而且 也 不 好吃   特别 是 鸡肉 卷   * * 都 不想...  少送 一个 牛肉 汉堡   而且 也 不 好吃   特别 是 鸡肉 卷   * * 都 不想..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_gen/train.txt', 'w', encoding='utf8') as f:\n",
    "    f.writelines(df.train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('data_gen/train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data_origin/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['comment_seg'] = df_test.comment.map(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_seg</th>\n",
       "      <th>result</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011f384-9e54-4fb4-a272-330a6cab6804</td>\n",
       "      <td>糯米团是我小时候的记忆了，吃起还是好吃，只是小时候的油条没有这么硬！油茶也还好！可以试试</td>\n",
       "      <td>糯米 团是 我 小时候 的 记忆 了 ， 吃 起 还是 好吃 ， 只是 小时候 的 油条 没...</td>\n",
       "      <td>((__label__0,), [0.9305034875869751])</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00223e4f-47e1-4fc8-9657-06444a7de9a5</td>\n",
       "      <td>满满的五星好评，口味好，服务好，特别喜欢，昨天第一次买，今天就回购了，买的刨奶，店长问我加腰...</td>\n",
       "      <td>满满的 五星 好评 ， 口味 好 ， 服务 好 ， 特别 喜欢 ， 昨天 第一次 买 ， 今...</td>\n",
       "      <td>((__label__0,), [0.9706935286521912])</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00225350-c169-435c-84cf-970068df5b12</td>\n",
       "      <td>好喝！经常会再去买来喝！就是排队的人太多了</td>\n",
       "      <td>好喝 ！ 经常 会 再 去 买来 喝 ！ 就是 排队 的 人太多 了</td>\n",
       "      <td>((__label__0,), [0.9995092153549194])</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a3190c-90c1-44c3-b809-7a9b1314cd27</td>\n",
       "      <td>三个人订的四人餐，菜量大没吃完，问道不错。</td>\n",
       "      <td>三个 人订 的 四人餐 ， 菜量 大 没 吃 完 ， 问道 不错 。</td>\n",
       "      <td>((__label__0,), [0.9895778298377991])</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b3f76e-fda3-42cd-8884-25e03a5dba64</td>\n",
       "      <td>好的一如既往，真真爱上了自助炒饭自助八宝粥自助冰粉！！！喜欢所有菜和肉，两女一男吃两份两人餐...</td>\n",
       "      <td>好 的 一如既往 ， 真真 爱上 了 自助 炒饭 自助 八宝粥 自助 冰粉 ！ ！ ！ 喜欢...</td>\n",
       "      <td>((__label__0,), [0.994170606136322])</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                                            comment                                        comment_seg                                 result label\n",
       "0  0011f384-9e54-4fb4-a272-330a6cab6804       糯米团是我小时候的记忆了，吃起还是好吃，只是小时候的油条没有这么硬！油茶也还好！可以试试  糯米 团是 我 小时候 的 记忆 了 ， 吃 起 还是 好吃 ， 只是 小时候 的 油条 没...  ((__label__0,), [0.9305034875869751])     0\n",
       "1  00223e4f-47e1-4fc8-9657-06444a7de9a5  满满的五星好评，口味好，服务好，特别喜欢，昨天第一次买，今天就回购了，买的刨奶，店长问我加腰...  满满的 五星 好评 ， 口味 好 ， 服务 好 ， 特别 喜欢 ， 昨天 第一次 买 ， 今...  ((__label__0,), [0.9706935286521912])     0\n",
       "2  00225350-c169-435c-84cf-970068df5b12                              好喝！经常会再去买来喝！就是排队的人太多了                 好喝 ！ 经常 会 再 去 买来 喝 ！ 就是 排队 的 人太多 了  ((__label__0,), [0.9995092153549194])     0\n",
       "3  00a3190c-90c1-44c3-b809-7a9b1314cd27                              三个人订的四人餐，菜量大没吃完，问道不错。                 三个 人订 的 四人餐 ， 菜量 大 没 吃 完 ， 问道 不错 。  ((__label__0,), [0.9895778298377991])     0\n",
       "4  00b3f76e-fda3-42cd-8884-25e03a5dba64  好的一如既往，真真爱上了自助炒饭自助八宝粥自助冰粉！！！喜欢所有菜和肉，两女一男吃两份两人餐...  好 的 一如既往 ， 真真 爱上 了 自助 炒饭 自助 八宝粥 自助 冰粉 ！ ！ ！ 喜欢...   ((__label__0,), [0.994170606136322])     0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['result'] = df_test.comment_seg.map(model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test.result.str.get(0).str.get(0).str.get(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['id', 'label']].to_csv('data_gen/result_fasttext.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当前排名： 第 77 名 最高得分：0.86829270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label\tcomment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t一如既往地好吃，希望可以开到其他城市</td>\n",
       "      <td>0</td>\n",
       "      <td>一如既往地好吃，希望可以开到其他城市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t味道很不错，分量足，客人很多，满意</td>\n",
       "      <td>0</td>\n",
       "      <td>味道很不错，分量足，客人很多，满意</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...</td>\n",
       "      <td>0</td>\n",
       "      <td>下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t真心不好吃 基本上没得好多味道</td>\n",
       "      <td>0</td>\n",
       "      <td>真心不好吃 基本上没得好多味道</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "      <td>0</td>\n",
       "      <td>少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      label\\tcomment label                                            comment\n",
       "0                              0\\t一如既往地好吃，希望可以开到其他城市     0                                 一如既往地好吃，希望可以开到其他城市\n",
       "1                               0\\t味道很不错，分量足，客人很多，满意     0                                  味道很不错，分量足，客人很多，满意\n",
       "2  0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...     0  下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...\n",
       "3                                 0\\t真心不好吃 基本上没得好多味道     0                                    真心不好吃 基本上没得好多味道\n",
       "4           0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道     0              少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_origin/train.csv')\n",
    "df['label'] = df['label\\tcomment'].str.split('\\t').str.get(0)\n",
    "df['comment'] = df['label\\tcomment'].str.split('\\t').str.get(1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8489\n",
       "1    1511\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_seg'] = df.comment.map(jieba.lcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label\tcomment</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_seg</th>\n",
       "      <th>comment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t一如既往地好吃，希望可以开到其他城市</td>\n",
       "      <td>0</td>\n",
       "      <td>一如既往地好吃，希望可以开到其他城市</td>\n",
       "      <td>[一如既往, 地, 好吃, ，, 希望, 可以, 开, 到, 其他, 城市]</td>\n",
       "      <td>[71, 679, 15, 1, 193, 27, 719, 52, 156, 2778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t味道很不错，分量足，客人很多，满意</td>\n",
       "      <td>0</td>\n",
       "      <td>味道很不错，分量足，客人很多，满意</td>\n",
       "      <td>[味道, 很, 不错, ，, 分量, 足, ，, 客人, 很多, ，, 满意]</td>\n",
       "      <td>[10, 5, 12, 1, 42, 53, 1, 680, 109, 1, 96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...</td>\n",
       "      <td>0</td>\n",
       "      <td>下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...</td>\n",
       "      <td>[下雨天, 来, 的, ，, 没有, 想象, 中, 那么, 火爆, 。, 环境, 非常, 干...</td>\n",
       "      <td>[2432, 22, 2, 1, 29, 984, 525, 199, 1996, 6, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t真心不好吃 基本上没得好多味道</td>\n",
       "      <td>0</td>\n",
       "      <td>真心不好吃 基本上没得好多味道</td>\n",
       "      <td>[真心, 不, 好吃,  , 基本上, 没, 得, 好多, 味道]</td>\n",
       "      <td>[201, 19, 15, 4, 883, 40, 72, 284, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "      <td>0</td>\n",
       "      <td>少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道</td>\n",
       "      <td>[少送, 一个, 牛肉, 汉堡,  , 而且, 也, 不, 好吃,  , 特别, 是, 鸡肉...</td>\n",
       "      <td>[1997, 58, 143, 633, 4, 62, 11, 19, 15, 4, 49,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      label\\tcomment label                                            comment                                        comment_seg                                        comment_num\n",
       "0                              0\\t一如既往地好吃，希望可以开到其他城市     0                                 一如既往地好吃，希望可以开到其他城市             [一如既往, 地, 好吃, ，, 希望, 可以, 开, 到, 其他, 城市]      [71, 679, 15, 1, 193, 27, 719, 52, 156, 2778]\n",
       "1                               0\\t味道很不错，分量足，客人很多，满意     0                                  味道很不错，分量足，客人很多，满意            [味道, 很, 不错, ，, 分量, 足, ，, 客人, 很多, ，, 满意]         [10, 5, 12, 1, 42, 53, 1, 680, 109, 1, 96]\n",
       "2  0\\t下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我...     0  下雨天来的，没有想象中那么火爆。环境非常干净，古色古香的，我自己也是个做服务行业的，我都觉得...  [下雨天, 来, 的, ，, 没有, 想象, 中, 那么, 火爆, 。, 环境, 非常, 干...  [2432, 22, 2, 1, 29, 984, 525, 199, 1996, 6, 2...\n",
       "3                                 0\\t真心不好吃 基本上没得好多味道     0                                    真心不好吃 基本上没得好多味道                  [真心, 不, 好吃,  , 基本上, 没, 得, 好多, 味道]             [201, 19, 15, 4, 883, 40, 72, 284, 10]\n",
       "4           0\\t少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道     0              少送一个牛肉汉堡 而且也不好吃 特别是鸡肉卷 **都不想评论了 谁买谁知道  [少送, 一个, 牛肉, 汉堡,  , 而且, 也, 不, 好吃,  , 特别, 是, 鸡肉...  [1997, 58, 143, 633, 4, 62, 11, 19, 15, 4, 49,..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataset(words, vocabulary_size):\n",
    "    \"\"\"\n",
    "\n",
    "    :param words: 所有文章分词后的一个words list\n",
    "    :param vocabulary_size: 取频率最高的词数\n",
    "    :return:\n",
    "        data 编号列表，编号形式\n",
    "        count 前50000个出现次数最多的词\n",
    "        dictionary 词对应编号\n",
    "        reverse_dictionary 编号对应词\n",
    "    \"\"\"\n",
    "    count = [['<PAD>', -1], ['<UNK>', -1]]\n",
    "    # 前50000个出现次数最多的词\n",
    "    count.extend(Counter(words).most_common(vocabulary_size - 2))\n",
    "    # 生成 dictionary，词对应编号, word:id(0-49999)\n",
    "    # 词频越高编号越小\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    # data把数据集的词都编号\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 1  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    # 记录UNK词的数量\n",
    "    count[0][1] = unk_count\n",
    "    # 编号对应词的字典\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, count, dictionary, reverse_dictionary = buildDataset([ii for i in df.comment.map(jieba.lcut).tolist() for ii in i], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1(s):\n",
    "    return [dictionary[i] if i in dictionary else 0 for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_num'] = df.comment_seg.map(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df['comment_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=dictionary[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=64)\n",
    "\n",
    "# test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "#                                                        value=dictionary[\"<PAD>\"],\n",
    "#                                                        padding='post',\n",
    "#                                                        maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 321,057\n",
      "Trainable params: 321,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
    "vocab_size = 5000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 64))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:2000]\n",
    "partial_x_train = train_data[2000:]\n",
    "\n",
    "y_val = train_labels[:2000]\n",
    "partial_y_train = train_labels[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3000,   15,  120, ...,    0,    0,    0],\n",
       "       [  51,    9,    2, ...,    0,    0,    0],\n",
       "       [  26,   13,    2, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 402,   64,  430, ...,    0,    0,    0],\n",
       "       [  26,   11,    6, ...,    0,    0,    0],\n",
       "       [ 172, 1230,    2, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/40\n",
      "8000/8000 [==============================] - 0s 43us/sample - loss: 0.5871 - acc: 0.8475 - val_loss: 0.4763 - val_acc: 0.8545\n",
      "Epoch 2/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.4244 - acc: 0.8475 - val_loss: 0.3824 - val_acc: 0.8545\n",
      "Epoch 3/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3831 - acc: 0.8475 - val_loss: 0.3609 - val_acc: 0.8545\n",
      "Epoch 4/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3579 - acc: 0.8475 - val_loss: 0.3351 - val_acc: 0.8545\n",
      "Epoch 5/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3242 - acc: 0.8539 - val_loss: 0.2991 - val_acc: 0.8655\n",
      "Epoch 6/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2793 - acc: 0.8685 - val_loss: 0.2570 - val_acc: 0.8730\n",
      "Epoch 7/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2333 - acc: 0.8915 - val_loss: 0.2158 - val_acc: 0.9005\n",
      "Epoch 8/40\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.1863 - acc: 0.9222 - val_loss: 0.1830 - val_acc: 0.9275\n",
      "Epoch 9/40\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.1505 - acc: 0.9466 - val_loss: 0.1628 - val_acc: 0.9360\n",
      "Epoch 10/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.1245 - acc: 0.9595 - val_loss: 0.1499 - val_acc: 0.9445\n",
      "Epoch 11/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.1049 - acc: 0.9663 - val_loss: 0.1423 - val_acc: 0.9450\n",
      "Epoch 12/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.0898 - acc: 0.9731 - val_loss: 0.1370 - val_acc: 0.9450\n",
      "Epoch 13/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0780 - acc: 0.9775 - val_loss: 0.1341 - val_acc: 0.9500\n",
      "Epoch 14/40\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.0685 - acc: 0.9810 - val_loss: 0.1327 - val_acc: 0.9490\n",
      "Epoch 15/40\n",
      "8000/8000 [==============================] - 0s 26us/sample - loss: 0.0611 - acc: 0.9830 - val_loss: 0.1334 - val_acc: 0.9470\n",
      "Epoch 16/40\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.0541 - acc: 0.9846 - val_loss: 0.1325 - val_acc: 0.9490\n",
      "Epoch 17/40\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.0478 - acc: 0.9875 - val_loss: 0.1336 - val_acc: 0.9500\n",
      "Epoch 18/40\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.0428 - acc: 0.9890 - val_loss: 0.1345 - val_acc: 0.9500\n",
      "Epoch 19/40\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.0384 - acc: 0.9904 - val_loss: 0.1367 - val_acc: 0.9530\n",
      "Epoch 20/40\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.0347 - acc: 0.9909 - val_loss: 0.1370 - val_acc: 0.9530\n",
      "Epoch 21/40\n",
      "8000/8000 [==============================] - 0s 26us/sample - loss: 0.0319 - acc: 0.9921 - val_loss: 0.1388 - val_acc: 0.9540\n",
      "Epoch 22/40\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: 0.0284 - acc: 0.9931 - val_loss: 0.1410 - val_acc: 0.9510\n",
      "Epoch 23/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0263 - acc: 0.9937 - val_loss: 0.1425 - val_acc: 0.9525\n",
      "Epoch 24/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.0245 - acc: 0.9936 - val_loss: 0.1447 - val_acc: 0.9560\n",
      "Epoch 25/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.0221 - acc: 0.9955 - val_loss: 0.1492 - val_acc: 0.9555\n",
      "Epoch 26/40\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.0201 - acc: 0.9958 - val_loss: 0.1499 - val_acc: 0.9565\n",
      "Epoch 27/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.0184 - acc: 0.9964 - val_loss: 0.1522 - val_acc: 0.9570\n",
      "Epoch 28/40\n",
      "8000/8000 [==============================] - 0s 26us/sample - loss: 0.0172 - acc: 0.9960 - val_loss: 0.1545 - val_acc: 0.9540\n",
      "Epoch 29/40\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.0158 - acc: 0.9971 - val_loss: 0.1572 - val_acc: 0.9510\n",
      "Epoch 30/40\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: 0.0144 - acc: 0.9979 - val_loss: 0.1596 - val_acc: 0.9535\n",
      "Epoch 31/40\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.0125 - acc: 0.997 - 0s 25us/sample - loss: 0.0134 - acc: 0.9975 - val_loss: 0.1627 - val_acc: 0.9520\n",
      "Epoch 32/40\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.0128 - acc: 0.9979 - val_loss: 0.1662 - val_acc: 0.9560\n",
      "Epoch 33/40\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: 0.0116 - acc: 0.9981 - val_loss: 0.1671 - val_acc: 0.9535\n",
      "Epoch 34/40\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: 0.0107 - acc: 0.9986 - val_loss: 0.1706 - val_acc: 0.9535\n",
      "Epoch 35/40\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: 0.0100 - acc: 0.9986 - val_loss: 0.1729 - val_acc: 0.9535\n",
      "Epoch 36/40\n",
      "8000/8000 [==============================] - 0s 26us/sample - loss: 0.0095 - acc: 0.9991 - val_loss: 0.1770 - val_acc: 0.9545\n",
      "Epoch 37/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0089 - acc: 0.9989 - val_loss: 0.1800 - val_acc: 0.9500\n",
      "Epoch 38/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0082 - acc: 0.9990 - val_loss: 0.1826 - val_acc: 0.9525\n",
      "Epoch 39/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0078 - acc: 0.9992 - val_loss: 0.1841 - val_acc: 0.9530\n",
      "Epoch 40/40\n",
      "8000/8000 [==============================] - 0s 20us/sample - loss: 0.0072 - acc: 0.9992 - val_loss: 0.1869 - val_acc: 0.9525\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=200,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data_origin/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['comment_seg'] = df_test.comment.map(jieba.lcut)\n",
    "df_test['comment_num'] = df_test.comment_seg.map(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df_test.comment_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=dictionary[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['prob'] = model.predict(test_data).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_seg</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011f384-9e54-4fb4-a272-330a6cab6804</td>\n",
       "      <td>糯米团是我小时候的记忆了，吃起还是好吃，只是小时候的油条没有这么硬！油茶也还好！可以试试</td>\n",
       "      <td>[糯米, 团是, 我, 小时候, 的, 记忆, 了, ，, 吃, 起, 还是, 好吃, ，,...</td>\n",
       "      <td>[2116, 0, 17, 3356, 3, 4119, 4, 2, 10, 359, 34...</td>\n",
       "      <td>1.575291e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00223e4f-47e1-4fc8-9657-06444a7de9a5</td>\n",
       "      <td>满满的五星好评，口味好，服务好，特别喜欢，昨天第一次买，今天就回购了，买的刨奶，店长问我加腰...</td>\n",
       "      <td>[满满的, 五星, 好评, ，, 口味, 好, ，, 服务, 好, ，, 特别, 喜欢, ，...</td>\n",
       "      <td>[3039, 1145, 205, 2, 78, 9, 2, 25, 9, 2, 50, 3...</td>\n",
       "      <td>8.940697e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00225350-c169-435c-84cf-970068df5b12</td>\n",
       "      <td>好喝！经常会再去买来喝！就是排队的人太多了</td>\n",
       "      <td>[好喝, ！, 经常, 会, 再, 去, 买来, 喝, ！, 就是, 排队, 的, 人太多, 了]</td>\n",
       "      <td>[111, 8, 94, 115, 60, 21, 1559, 183, 8, 40, 28...</td>\n",
       "      <td>2.145767e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a3190c-90c1-44c3-b809-7a9b1314cd27</td>\n",
       "      <td>三个人订的四人餐，菜量大没吃完，问道不错。</td>\n",
       "      <td>[三个, 人订, 的, 四人餐, ，, 菜量, 大, 没, 吃, 完, ，, 问道, 不错, 。]</td>\n",
       "      <td>[258, 0, 3, 777, 2, 517, 216, 41, 10, 108, 2, ...</td>\n",
       "      <td>1.828074e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b3f76e-fda3-42cd-8884-25e03a5dba64</td>\n",
       "      <td>好的一如既往，真真爱上了自助炒饭自助八宝粥自助冰粉！！！喜欢所有菜和肉，两女一男吃两份两人餐...</td>\n",
       "      <td>[好, 的, 一如既往, ，, 真真, 爱上, 了, 自助, 炒饭, 自助, 八宝粥, 自助...</td>\n",
       "      <td>[9, 3, 72, 2, 0, 2456, 4, 426, 437, 426, 3000,...</td>\n",
       "      <td>1.788139e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                                            comment                                        comment_seg                                        comment_num          prob\n",
       "0  0011f384-9e54-4fb4-a272-330a6cab6804       糯米团是我小时候的记忆了，吃起还是好吃，只是小时候的油条没有这么硬！油茶也还好！可以试试  [糯米, 团是, 我, 小时候, 的, 记忆, 了, ，, 吃, 起, 还是, 好吃, ，,...  [2116, 0, 17, 3356, 3, 4119, 4, 2, 10, 359, 34...  1.575291e-03\n",
       "1  00223e4f-47e1-4fc8-9657-06444a7de9a5  满满的五星好评，口味好，服务好，特别喜欢，昨天第一次买，今天就回购了，买的刨奶，店长问我加腰...  [满满的, 五星, 好评, ，, 口味, 好, ，, 服务, 好, ，, 特别, 喜欢, ，...  [3039, 1145, 205, 2, 78, 9, 2, 25, 9, 2, 50, 3...  8.940697e-08\n",
       "2  00225350-c169-435c-84cf-970068df5b12                              好喝！经常会再去买来喝！就是排队的人太多了  [好喝, ！, 经常, 会, 再, 去, 买来, 喝, ！, 就是, 排队, 的, 人太多, 了]  [111, 8, 94, 115, 60, 21, 1559, 183, 8, 40, 28...  2.145767e-06\n",
       "3  00a3190c-90c1-44c3-b809-7a9b1314cd27                              三个人订的四人餐，菜量大没吃完，问道不错。  [三个, 人订, 的, 四人餐, ，, 菜量, 大, 没, 吃, 完, ，, 问道, 不错, 。]  [258, 0, 3, 777, 2, 517, 216, 41, 10, 108, 2, ...  1.828074e-04\n",
       "4  00b3f76e-fda3-42cd-8884-25e03a5dba64  好的一如既往，真真爱上了自助炒饭自助八宝粥自助冰粉！！！喜欢所有菜和肉，两女一男吃两份两人餐...  [好, 的, 一如既往, ，, 真真, 爱上, 了, 自助, 炒饭, 自助, 八宝粥, 自助...  [9, 3, 72, 2, 0, 2456, 4, 426, 437, 426, 3000,...  1.788139e-07"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = np.where(df_test['prob']>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1713\n",
       "1     287\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['id', 'label']].to_csv('data_gen/result_tfkeras.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.85579200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
